{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d026541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      " Accuracy     0.761499\n",
      "Precision    0.749036\n",
      "Recall       0.792237\n",
      "F1 Score     0.768806\n",
      "MCC          0.526134\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " Accuracy     0.021702\n",
      "Precision    0.036836\n",
      "Recall       0.039751\n",
      "F1 Score     0.020419\n",
      "MCC          0.043882\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    \"\"\"Load sequence data from a file and label it.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().split(\"\\n\")\n",
    "    # Assuming each line in the file is a sequence\n",
    "    data = [list(sequence) for sequence in sequences if sequence]  # Exclude any empty lines\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = label\n",
    "    return df\n",
    "\n",
    "# Load and label positive and negative data\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "\n",
    "# Combine the data\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "\n",
    "# One-hot encoding and XGBoost model pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')),  # Set handle_unknown='ignore'\n",
    "    ('model', XGBClassifier(\n",
    "        colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_depth=None,\n",
    "        min_child_weight=5, n_estimators=300, subsample=1.0, n_jobs=-1, random_state=101\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Perform KFold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=101)\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    pipeline.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = pipeline.predict(X_val_fold)\n",
    "\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "    precision = precision_score(y_val_fold, y_pred)\n",
    "    recall = recall_score(y_val_fold, y_pred)\n",
    "    f1 = f1_score(y_val_fold, y_pred)\n",
    "    mcc = matthews_corrcoef(y_val_fold, y_pred)\n",
    "\n",
    "    results.append([accuracy, precision, recall, f1, mcc])\n",
    "\n",
    "# Convert results to a DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results, columns=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'MCC'])\n",
    "\n",
    "# Calculate mean and standard deviation of metrics\n",
    "mean_results = results_df.mean()\n",
    "std_results = results_df.std()\n",
    "\n",
    "print(\"Cross-Validation Results:\\n\", mean_results)\n",
    "print(\"\\nStandard Deviations:\\n\", std_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205db55c-4db8-45b8-9b78-7aacbe2a56df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVM:\n",
      "Accuracy: 0.6528\n",
      "Precision: 0.6578\n",
      "Recall: 0.6441\n",
      "F1 Score: 0.6500\n",
      "MCC: 0.3068\n",
      "\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 0.5883\n",
      "Precision: 0.5949\n",
      "Recall: 0.5675\n",
      "F1 Score: 0.5797\n",
      "MCC: 0.1787\n",
      "\n",
      "\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.6096\n",
      "Precision: 0.6136\n",
      "Recall: 0.6010\n",
      "F1 Score: 0.6063\n",
      "MCC: 0.2206\n",
      "\n",
      "\n",
      "Results for Naive Bayes:\n",
      "Accuracy: 0.6524\n",
      "Precision: 0.6586\n",
      "Recall: 0.6383\n",
      "F1 Score: 0.6476\n",
      "MCC: 0.3057\n",
      "\n",
      "\n",
      "Results for K-NN:\n",
      "Accuracy: 0.5846\n",
      "Precision: 0.6146\n",
      "Recall: 0.4648\n",
      "F1 Score: 0.5279\n",
      "MCC: 0.1763\n",
      "\n",
      "\n",
      "Results for GBM:\n",
      "Accuracy: 0.6245\n",
      "Precision: 0.6302\n",
      "Recall: 0.6075\n",
      "F1 Score: 0.6180\n",
      "MCC: 0.2497\n",
      "\n",
      "\n",
      "Results for AdaBoost:\n",
      "Accuracy: 0.6042\n",
      "Precision: 0.6050\n",
      "Recall: 0.6007\n",
      "F1 Score: 0.6021\n",
      "MCC: 0.2088\n",
      "\n",
      "\n",
      "Results for Decision Tree:\n",
      "Accuracy: 0.5245\n",
      "Precision: 0.5264\n",
      "Recall: 0.5177\n",
      "F1 Score: 0.5209\n",
      "MCC: 0.0505\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    \"\"\"Load sequence data from a file and label it.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().split(\"\\n\")\n",
    "    data = [list(sequence) for sequence in sequences if sequence]  # Exclude any empty lines\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = label\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load and label positive and negative data\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "\n",
    "# Combine the data\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'SVM': lambda: SVC(probability=True, random_state=101),\n",
    "    'Random Forest': lambda: RandomForestClassifier(n_estimators=100, random_state=101),\n",
    "    'Logistic Regression': lambda: LogisticRegression(random_state=101),\n",
    "    'Naive Bayes': lambda: GaussianNB(),\n",
    "    'K-NN': lambda: KNeighborsClassifier(n_neighbors=5),\n",
    "    'GBM': lambda: GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': lambda: AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': lambda: DecisionTreeClassifier(random_state=101)\n",
    "}\n",
    "\n",
    "def evaluate_classifier(X_train, y_train, classifier_func):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=101)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('encoder', OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')),\n",
    "            ('model', classifier_func())\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = pipeline.predict(X_val_fold)\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(y_val_fold, y_pred),\n",
    "            'Precision': precision_score(y_val_fold, y_pred),\n",
    "            'Recall': recall_score(y_val_fold, y_pred),\n",
    "            'F1 Score': f1_score(y_val_fold, y_pred),\n",
    "            'MCC': matthews_corrcoef(y_val_fold, y_pred)\n",
    "        }\n",
    "        \n",
    "        results.append(metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "final_results = {}\n",
    "\n",
    "for name, classifier_func in classifiers.items():\n",
    "    results = evaluate_classifier(X_train, y_train, classifier_func)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    mean_results = results_df.mean().to_dict()\n",
    "    final_results[name] = mean_results\n",
    "\n",
    "# Print final results for all classifiers\n",
    "for classifier, metrics in final_results.items():\n",
    "    print(f\"Results for {classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb50607-b1f0-4f02-8576-c90f92cd88c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.3-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.3-cp311-cp311-win_amd64.whl (101.1 MB)\n",
      "   ---------------------------------------- 0.0/101.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/101.1 MB 991.0 kB/s eta 0:01:42\n",
      "   ---------------------------------------- 0.1/101.1 MB 1.7 MB/s eta 0:01:02\n",
      "   ---------------------------------------- 0.2/101.1 MB 1.4 MB/s eta 0:01:12\n",
      "   ---------------------------------------- 0.2/101.1 MB 1.3 MB/s eta 0:01:21\n",
      "   ---------------------------------------- 0.3/101.1 MB 1.2 MB/s eta 0:01:24\n",
      "   ---------------------------------------- 0.4/101.1 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 0.4/101.1 MB 1.4 MB/s eta 0:01:13\n",
      "   ---------------------------------------- 0.6/101.1 MB 1.5 MB/s eta 0:01:07\n",
      "   ---------------------------------------- 0.7/101.1 MB 1.7 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 0.8/101.1 MB 1.7 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 0.9/101.1 MB 1.7 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 1.0/101.1 MB 1.7 MB/s eta 0:00:59\n",
      "   ---------------------------------------- 1.1/101.1 MB 1.8 MB/s eta 0:00:56\n",
      "   ---------------------------------------- 1.1/101.1 MB 1.8 MB/s eta 0:00:57\n",
      "    --------------------------------------- 1.3/101.1 MB 1.8 MB/s eta 0:00:55\n",
      "    --------------------------------------- 1.4/101.1 MB 1.8 MB/s eta 0:00:56\n",
      "    --------------------------------------- 1.4/101.1 MB 1.8 MB/s eta 0:00:56\n",
      "    --------------------------------------- 1.6/101.1 MB 1.8 MB/s eta 0:00:55\n",
      "    --------------------------------------- 1.6/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "    --------------------------------------- 1.7/101.1 MB 1.9 MB/s eta 0:00:54\n",
      "    --------------------------------------- 1.8/101.1 MB 1.8 MB/s eta 0:00:55\n",
      "    --------------------------------------- 1.9/101.1 MB 1.8 MB/s eta 0:00:55\n",
      "    --------------------------------------- 2.0/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "    --------------------------------------- 2.1/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "    --------------------------------------- 2.2/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "    --------------------------------------- 2.3/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "    --------------------------------------- 2.4/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "    --------------------------------------- 2.5/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 2.6/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 2.7/101.1 MB 1.9 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 2.9/101.1 MB 1.9 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 2.9/101.1 MB 1.9 MB/s eta 0:00:52\n",
      "   - -------------------------------------- 3.0/101.1 MB 1.9 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.1/101.1 MB 1.9 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.2/101.1 MB 2.0 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 3.3/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 3.5/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 3.6/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 3.7/101.1 MB 2.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 3.8/101.1 MB 2.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 3.9/101.1 MB 2.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 4.0/101.1 MB 2.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 4.1/101.1 MB 2.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 4.2/101.1 MB 2.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 4.3/101.1 MB 2.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 4.3/101.1 MB 2.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 4.4/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 4.5/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 4.5/101.1 MB 2.0 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 4.6/101.1 MB 1.9 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 4.6/101.1 MB 1.9 MB/s eta 0:00:52\n",
      "   - -------------------------------------- 4.7/101.1 MB 1.9 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 4.7/101.1 MB 1.8 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 4.8/101.1 MB 1.8 MB/s eta 0:00:53\n",
      "   - -------------------------------------- 4.8/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 4.9/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 4.9/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 5.0/101.1 MB 1.8 MB/s eta 0:00:54\n",
      "   - -------------------------------------- 5.0/101.1 MB 1.8 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 5.1/101.1 MB 1.7 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 5.2/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.2/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.3/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.3/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.4/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.5/101.1 MB 1.7 MB/s eta 0:00:56\n",
      "   -- ------------------------------------- 5.5/101.1 MB 1.7 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 5.6/101.1 MB 1.7 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 5.6/101.1 MB 1.7 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 5.7/101.1 MB 1.7 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 5.8/101.1 MB 1.7 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 5.8/101.1 MB 1.7 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 5.9/101.1 MB 1.6 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 5.9/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.0/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.0/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.1/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.1/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.2/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.3/101.1 MB 1.6 MB/s eta 0:00:59\n",
      "   -- ------------------------------------- 6.3/101.1 MB 1.6 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.3/101.1 MB 1.6 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.4/101.1 MB 1.6 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.5/101.1 MB 1.6 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 6.5/101.1 MB 1.6 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 6.6/101.1 MB 1.6 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 6.6/101.1 MB 1.6 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 6.6/101.1 MB 1.6 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 6.7/101.1 MB 1.5 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 6.7/101.1 MB 1.5 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 6.8/101.1 MB 1.5 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 6.8/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 6.9/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 6.9/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 6.9/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 7.0/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 7.1/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 7.1/101.1 MB 1.5 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 7.1/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 7.2/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 7.3/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 7.3/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 7.4/101.1 MB 1.5 MB/s eta 0:01:05\n",
      "   -- ------------------------------------- 7.4/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   -- ------------------------------------- 7.5/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 7.6/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 7.7/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 7.7/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 7.8/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 7.8/101.1 MB 1.5 MB/s eta 0:01:04\n",
      "   --- ------------------------------------ 7.9/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.0/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.0/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.1/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.1/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.2/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.2/101.1 MB 1.4 MB/s eta 0:01:05\n",
      "   --- ------------------------------------ 8.3/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.3/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.4/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.4/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.5/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.5/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.6/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.6/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.7/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.7/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.8/101.1 MB 1.4 MB/s eta 0:01:06\n",
      "   --- ------------------------------------ 8.8/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 8.9/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 8.9/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.0/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.0/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.1/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.1/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.2/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.2/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.3/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.3/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.3/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.4/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.5/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.6/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.6/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.7/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.8/101.1 MB 1.4 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 9.8/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.9/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.9/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 9.9/101.1 MB 1.4 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 10.0/101.1 MB 1.3 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 10.1/101.1 MB 1.3 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 10.1/101.1 MB 1.3 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 10.1/101.1 MB 1.3 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 10.2/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.2/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.3/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.4/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.4/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.4/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.5/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.5/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.6/101.1 MB 1.3 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 10.6/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.7/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.7/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.8/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.8/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.9/101.1 MB 1.3 MB/s eta 0:01:10\n",
      "   ---- ----------------------------------- 10.9/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.0/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.0/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.1/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.1/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.2/101.1 MB 1.3 MB/s eta 0:01:11\n",
      "   ---- ----------------------------------- 11.2/101.1 MB 1.3 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 11.3/101.1 MB 1.3 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 1.3 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 1.2 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 11.5/101.1 MB 1.2 MB/s eta 0:01:12\n",
      "   ---- ----------------------------------- 11.5/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.6/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.7/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.7/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.8/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.9/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 11.9/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 12.0/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ---- ----------------------------------- 12.0/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.0/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.1/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.1/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.2/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.2/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ---- ----------------------------------- 12.3/101.1 MB 1.2 MB/s eta 0:01:15\n",
      "   ---- ----------------------------------- 12.3/101.1 MB 1.2 MB/s eta 0:01:15\n",
      "   ---- ----------------------------------- 12.3/101.1 MB 1.2 MB/s eta 0:01:15\n",
      "   ---- ----------------------------------- 12.4/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 12.4/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 12.5/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 12.5/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 12.6/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 12.7/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 12.7/101.1 MB 1.2 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 12.8/101.1 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 12.8/101.1 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 12.9/101.1 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 12.9/101.1 MB 1.1 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 13.0/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.0/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.1/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.2/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.2/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.2/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.3/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 13.3/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 13.4/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 13.5/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 13.5/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 13.6/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ----- ---------------------------------- 13.6/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.7/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.7/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.8/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.8/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 13.9/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 14.0/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.1/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.1/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.2/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.2/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.3/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.3/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.4/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.4/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 14.5/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.5/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.6/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.7/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.8/101.1 MB 1.1 MB/s eta 0:01:22\n",
      "   ----- ---------------------------------- 14.8/101.1 MB 1.1 MB/s eta 0:01:21\n",
      "   ----- ---------------------------------- 15.0/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 15.0/101.1 MB 1.1 MB/s eta 0:01:20\n",
      "   ----- ---------------------------------- 15.1/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 15.2/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 15.3/101.1 MB 1.1 MB/s eta 0:01:19\n",
      "   ------ --------------------------------- 15.5/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ------ --------------------------------- 15.6/101.1 MB 1.1 MB/s eta 0:01:18\n",
      "   ------ --------------------------------- 15.7/101.1 MB 1.1 MB/s eta 0:01:17\n",
      "   ------ --------------------------------- 15.8/101.1 MB 1.1 MB/s eta 0:01:17\n",
      "   ------ --------------------------------- 15.9/101.1 MB 1.1 MB/s eta 0:01:16\n",
      "   ------ --------------------------------- 16.0/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.1/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.1/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.2/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.2/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.4/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.5/101.1 MB 1.1 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.6/101.1 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 16.7/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 16.8/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 16.9/101.1 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 16.9/101.1 MB 1.2 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 17.0/101.1 MB 1.2 MB/s eta 0:01:12\n",
      "   ------ --------------------------------- 17.1/101.1 MB 1.2 MB/s eta 0:01:11\n",
      "   ------ --------------------------------- 17.2/101.1 MB 1.2 MB/s eta 0:01:11\n",
      "   ------ --------------------------------- 17.3/101.1 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 17.4/101.1 MB 1.2 MB/s eta 0:01:10\n",
      "   ------ --------------------------------- 17.5/101.1 MB 1.2 MB/s eta 0:01:09\n",
      "   ------ --------------------------------- 17.7/101.1 MB 1.2 MB/s eta 0:01:09\n",
      "   ------- -------------------------------- 17.8/101.1 MB 1.2 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 17.9/101.1 MB 1.2 MB/s eta 0:01:08\n",
      "   ------- -------------------------------- 18.0/101.1 MB 1.2 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 18.1/101.1 MB 1.2 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 18.2/101.1 MB 1.3 MB/s eta 0:01:07\n",
      "   ------- -------------------------------- 18.3/101.1 MB 1.3 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 18.4/101.1 MB 1.3 MB/s eta 0:01:06\n",
      "   ------- -------------------------------- 18.5/101.1 MB 1.3 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 18.6/101.1 MB 1.3 MB/s eta 0:01:05\n",
      "   ------- -------------------------------- 18.7/101.1 MB 1.3 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 18.8/101.1 MB 1.3 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 18.9/101.1 MB 1.3 MB/s eta 0:01:04\n",
      "   ------- -------------------------------- 19.0/101.1 MB 1.3 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 19.1/101.1 MB 1.3 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 19.3/101.1 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.3/101.1 MB 1.3 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 19.4/101.1 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.5/101.1 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.6/101.1 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.7/101.1 MB 1.4 MB/s eta 0:01:00\n",
      "   ------- -------------------------------- 19.7/101.1 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.8/101.1 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 19.9/101.1 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 20.0/101.1 MB 1.4 MB/s eta 0:00:59\n",
      "   ------- -------------------------------- 20.1/101.1 MB 1.4 MB/s eta 0:00:58\n",
      "   ------- -------------------------------- 20.2/101.1 MB 1.4 MB/s eta 0:00:58\n",
      "   -------- ------------------------------- 20.3/101.1 MB 1.4 MB/s eta 0:00:57\n",
      "   -------- ------------------------------- 20.4/101.1 MB 1.4 MB/s eta 0:00:57\n",
      "   -------- ------------------------------- 20.5/101.1 MB 1.4 MB/s eta 0:00:57\n",
      "   -------- ------------------------------- 20.6/101.1 MB 1.4 MB/s eta 0:00:56\n",
      "   -------- ------------------------------- 20.7/101.1 MB 1.5 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 20.8/101.1 MB 1.5 MB/s eta 0:00:55\n",
      "   -------- ------------------------------- 20.9/101.1 MB 1.5 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 21.0/101.1 MB 1.5 MB/s eta 0:00:54\n",
      "   -------- ------------------------------- 21.1/101.1 MB 1.5 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 21.2/101.1 MB 1.5 MB/s eta 0:00:53\n",
      "   -------- ------------------------------- 21.3/101.1 MB 1.5 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 21.5/101.1 MB 1.6 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 21.5/101.1 MB 1.6 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 21.7/101.1 MB 1.6 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 21.7/101.1 MB 1.6 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 21.9/101.1 MB 1.6 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 21.9/101.1 MB 1.6 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 22.0/101.1 MB 1.6 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 22.1/101.1 MB 1.6 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 22.2/101.1 MB 1.6 MB/s eta 0:00:49\n",
      "   -------- ------------------------------- 22.3/101.1 MB 1.7 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 22.4/101.1 MB 1.7 MB/s eta 0:00:48\n",
      "   -------- ------------------------------- 22.5/101.1 MB 1.7 MB/s eta 0:00:47\n",
      "   -------- ------------------------------- 22.7/101.1 MB 1.7 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 22.8/101.1 MB 1.7 MB/s eta 0:00:46\n",
      "   --------- ------------------------------ 22.9/101.1 MB 1.8 MB/s eta 0:00:45\n",
      "   --------- ------------------------------ 23.0/101.1 MB 1.8 MB/s eta 0:00:45\n",
      "   --------- ------------------------------ 23.1/101.1 MB 1.8 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 23.2/101.1 MB 1.8 MB/s eta 0:00:44\n",
      "   --------- ------------------------------ 23.3/101.1 MB 1.8 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 23.4/101.1 MB 1.8 MB/s eta 0:00:43\n",
      "   --------- ------------------------------ 23.5/101.1 MB 1.9 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 23.6/101.1 MB 1.9 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 23.7/101.1 MB 1.9 MB/s eta 0:00:42\n",
      "   --------- ------------------------------ 23.8/101.1 MB 1.9 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 23.9/101.1 MB 1.9 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 24.0/101.1 MB 1.9 MB/s eta 0:00:41\n",
      "   --------- ------------------------------ 24.1/101.1 MB 1.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 24.2/101.1 MB 1.9 MB/s eta 0:00:40\n",
      "   --------- ------------------------------ 24.4/101.1 MB 2.0 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 24.5/101.1 MB 2.0 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 24.6/101.1 MB 2.0 MB/s eta 0:00:39\n",
      "   --------- ------------------------------ 24.7/101.1 MB 2.0 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 24.8/101.1 MB 2.0 MB/s eta 0:00:38\n",
      "   --------- ------------------------------ 24.9/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 25.0/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 25.1/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   --------- ------------------------------ 25.2/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.3/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.4/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.5/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.6/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.7/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 25.9/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 26.0/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 26.0/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 26.2/101.1 MB 2.1 MB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 26.3/101.1 MB 2.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 26.4/101.1 MB 2.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 26.5/101.1 MB 2.1 MB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 26.6/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 26.7/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 26.9/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 26.9/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.1/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.2/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.3/101.1 MB 2.2 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.4/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.5/101.1 MB 2.2 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.6/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ---------- ----------------------------- 27.7/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 27.8/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 28.0/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 28.0/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 28.1/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 28.2/101.1 MB 2.1 MB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 28.3/101.1 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 28.4/101.1 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 28.5/101.1 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 28.7/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 28.8/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 28.9/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.0/101.1 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.1/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.1 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 2.2 MB/s eta 0:00:34\n",
      "   ----------- ---------------------------- 29.3/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.4/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.9 MB/s eta 0:00:38\n",
      "   ----------- ---------------------------- 29.5/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 29.6/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 29.7/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 29.8/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 29.9/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 30.0/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 30.1/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 30.2/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 30.3/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 30.4/101.1 MB 1.6 MB/s eta 0:00:46\n",
      "   ------------ --------------------------- 30.5/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 30.6/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 30.7/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 30.8/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 30.9/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.0/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.1/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.3/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.4/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.5/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.6/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.7/101.1 MB 1.6 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 31.8/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 31.9/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.0/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.1/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.2/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.4/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.4/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.5/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.6/101.1 MB 1.6 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 32.7/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 32.8/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.0/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.1/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.2/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.2/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.4/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.6/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.7/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.8/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 33.9/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 34.0/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 34.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 34.2/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 34.3/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 34.4/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 34.5/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 34.5/101.1 MB 1.6 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 34.7/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 34.8/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 34.9/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 35.0/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 35.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 35.2/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 35.3/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.4/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.5/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.6/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.7/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.8/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 35.9/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.0/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.6 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.2 MB/s eta 0:00:55\n",
      "   -------------- ------------------------- 36.1/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.2/101.1 MB 1.2 MB/s eta 0:00:55\n",
      "   -------------- ------------------------- 36.3/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.3/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.4/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.5/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.6/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.7/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.7/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.8/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.8/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 36.9/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.0/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.1/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.2/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.3/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.3/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.4/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.5/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.6/101.1 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.7/101.1 MB 1.2 MB/s eta 0:00:55\n",
      "   -------------- ------------------------- 37.8/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 37.9/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 37.9/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 38.1/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 38.1/101.1 MB 1.1 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 38.2/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.3/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.4/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.5/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.6/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.7/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.8/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 38.9/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.0/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.2/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.2/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.3/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.4/101.1 MB 1.1 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 39.5/101.1 MB 1.2 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 39.7/101.1 MB 1.2 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 39.7/101.1 MB 1.2 MB/s eta 0:00:51\n",
      "   --------------- ------------------------ 39.8/101.1 MB 1.4 MB/s eta 0:00:44\n",
      "   --------------- ------------------------ 40.0/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 40.0/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 40.2/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 40.2/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   --------------- ------------------------ 40.4/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.5/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.6/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.7/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.7/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.8/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 40.9/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.0/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.1/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.3/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.3/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.4/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 41.5/101.1 MB 1.4 MB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 41.6/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 41.7/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 41.9/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.0/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.1/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.2/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.3/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.4/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.5/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.6/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.7/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ---------------- ----------------------- 42.8/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ---------------- ----------------------- 42.9/101.1 MB 1.4 MB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 43.0/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.1/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.2/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.3/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.4/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.5/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.6/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.7/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 43.9/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.0/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.1/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.2/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.3/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.4/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.5/101.1 MB 1.4 MB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 44.6/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 44.7/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 44.8/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 44.9/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 45.0/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 45.1/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 45.2/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 45.3/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ----------------- ---------------------- 45.4/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 45.5/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 45.6/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 45.7/101.1 MB 1.4 MB/s eta 0:00:40\n",
      "   ------------------ --------------------- 45.8/101.1 MB 1.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 46.0/101.1 MB 1.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 46.0/101.1 MB 1.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 46.1/101.1 MB 1.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 46.2/101.1 MB 1.4 MB/s eta 0:00:39\n",
      "   ------------------ --------------------- 46.3/101.1 MB 2.0 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 46.4/101.1 MB 2.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 46.6/101.1 MB 2.0 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 46.7/101.1 MB 2.1 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 46.7/101.1 MB 2.1 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 46.8/101.1 MB 2.1 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 47.0/101.1 MB 2.1 MB/s eta 0:00:27\n",
      "   ------------------ --------------------- 47.0/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.2/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.3/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.4/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.5/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.6/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.7/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.8/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------ --------------------- 47.9/101.1 MB 2.1 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 48.0/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.1/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.2/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.3/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.4/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.5/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.6/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.7/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.8/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 48.9/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.0/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.1/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.2/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.3/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.4/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.5/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.6/101.1 MB 2.1 MB/s eta 0:00:25\n",
      "   ------------------- -------------------- 49.8/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 49.9/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.0/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.1/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.2/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.3/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.4/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   ------------------- -------------------- 50.5/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 50.6/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 50.7/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 50.8/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 50.9/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.0/101.1 MB 2.2 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.1/101.1 MB 2.2 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.2/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.4/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.5/101.1 MB 2.1 MB/s eta 0:00:24\n",
      "   -------------------- ------------------- 51.6/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 51.7/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 51.8/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 51.9/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.0/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.2/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.3/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.4/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.5/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.6/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.7/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.8/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 52.9/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   -------------------- ------------------- 53.0/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 53.1/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 53.2/101.1 MB 2.2 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 53.4/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.5/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.6/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.7/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.8/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.8/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 53.9/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.0/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.2/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.3/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.4/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.5/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.6/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.7/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.7/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 54.8/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.0/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.0/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.1/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.2/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.3/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.4/101.1 MB 2.2 MB/s eta 0:00:22\n",
      "   --------------------- ------------------ 55.5/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 55.6/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 55.7/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 55.8/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 55.9/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 56.0/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 56.1/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 56.2/101.1 MB 2.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 56.2/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.4/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.5/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.6/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.7/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.8/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 56.9/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.0/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.1/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.1/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.2/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.3/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.4/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.5/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.6/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.7/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.8/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.8/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 57.9/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 58.0/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ---------------------- ----------------- 58.0/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.2/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.3/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.5/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.5/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.6/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.7/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.8/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 58.9/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 59.0/101.1 MB 2.1 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 59.2/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.3/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.4/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.5/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.6/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.7/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 59.9/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.0/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.1/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.1/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.2/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.4/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.5/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 60.6/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 60.7/101.1 MB 2.1 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 60.8/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 60.9/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.0/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.1/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.2/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.3/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.5/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.6/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.7/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.8/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 61.9/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.0/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.1/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.2/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.2/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.4/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.5/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.6/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.7/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.8/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 62.9/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.0/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 63.1/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 63.2/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 63.3/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 63.4/101.1 MB 2.1 MB/s eta 0:00:19\n",
      "   ------------------------- -------------- 63.5/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 63.6/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 63.7/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 63.8/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 63.9/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.0/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.1/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.2/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.3/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.5/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.6/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.7/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.8/101.1 MB 2.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 64.9/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.0/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.1/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.2/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.3/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.5/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.6/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   ------------------------- -------------- 65.7/101.1 MB 2.1 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 65.8/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 65.9/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 66.0/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 66.2/101.1 MB 2.2 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 66.3/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.4/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.4/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.6/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.6/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.7/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.8/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 66.9/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.1/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.2/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.3/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.4/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.5/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.6/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.7/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 67.9/101.1 MB 2.2 MB/s eta 0:00:16\n",
      "   -------------------------- ------------- 68.0/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 68.1/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   -------------------------- ------------- 68.2/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.3/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.4/101.1 MB 2.3 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.5/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.6/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.7/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.8/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 68.9/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.0/101.1 MB 2.3 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.1/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.2/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.3/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.4/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.5/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.6/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.7/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.7/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.9/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 69.9/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 70.1/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 70.1/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 70.3/101.1 MB 2.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 70.4/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.5/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.6/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 70.7/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 70.8/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 70.9/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.0/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.1/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.2/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.3/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.5/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.6/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.7/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.8/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.8/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 71.9/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.0/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.1/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.2/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.3/101.1 MB 2.1 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.5/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.6/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.7/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.8/101.1 MB 2.2 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 72.9/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 73.0/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 73.1/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 73.2/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 73.3/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.3/101.1 MB 2.2 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.4/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.5/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.6/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.7/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.8/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.9/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 73.9/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.0/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.1/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.2/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.3/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.4/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.4/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.5/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.6/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.6/101.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.7/101.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.8/101.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 74.8/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 74.9/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.0/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.1/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.2/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.2/101.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 75.3/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.4/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.4/101.1 MB 2.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.5/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.5/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.6/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.7/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 75.8/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 75.9/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 75.9/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.0/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.1/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.1/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.2/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.3/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.3/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.5/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.5/101.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.6/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.6/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.7/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.8/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.9/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 76.9/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.0/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.1/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.2/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.3/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.3/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.4/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.5/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.6/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.6/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.7/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.8/101.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.9/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 77.9/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 78.0/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 78.1/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 78.2/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 78.2/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 78.3/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.4/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.4/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.5/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.6/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.6/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.8/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.8/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 78.9/101.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.0/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.0/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.1/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.2/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.3/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.4/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.5/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.5/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.6/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.6/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.7/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.8/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.8/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 79.9/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.0/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.0/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.1/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.2/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.2/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.3/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.3/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.4/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.5/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.6/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.7/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.7/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 80.8/101.1 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 80.9/101.1 MB 1.6 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 80.9/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.0/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.0/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.1/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.2/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.2/101.1 MB 1.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 81.3/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.4/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.5/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.5/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.6/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.6/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.7/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.7/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.8/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.8/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.9/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 81.9/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.0/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.0/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.1/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.2/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.3/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.3/101.1 MB 1.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.4/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.4/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.4/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.5/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.6/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.6/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.7/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.7/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.8/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 82.9/101.1 MB 1.4 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 82.9/101.1 MB 1.4 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 83.0/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 83.1/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 83.1/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 83.2/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 83.3/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 83.3/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.4/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.5/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.5/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.6/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.7/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.7/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.8/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.9/101.1 MB 1.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.9/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 83.9/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.0/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.0/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.0/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.1/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.2/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.2/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.3/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.3/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.4/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.5/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.6/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.7/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.8/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 84.9/101.1 MB 1.3 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 85.0/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.1/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.2/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.3/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.4/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.5/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.5/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.6/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.6/101.1 MB 1.3 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.7/101.1 MB 1.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 85.9/101.1 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.0/101.1 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.0/101.1 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.1/101.1 MB 1.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 86.2/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.3/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.4/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.6/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.7/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.8/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 86.9/101.1 MB 1.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 87.0/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.1/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.2/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.4/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.5/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.6/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.7/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 87.8/101.1 MB 1.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 88.0/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 88.1/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 88.2/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 88.3/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 88.3/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 88.4/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 88.6/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 88.7/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 88.8/101.1 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 88.9/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.0/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.1/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.2/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.3/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.5/101.1 MB 1.5 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.5/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.7/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.8/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.8/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 89.9/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 90.0/101.1 MB 1.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 90.1/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.2/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.4/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.4/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.6/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.7/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.8/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 90.9/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 91.0/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 91.1/101.1 MB 1.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 91.2/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.4/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.5/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.6/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.7/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.8/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 91.9/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 92.0/101.1 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 92.1/101.1 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 92.2/101.1 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 92.3/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.4/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.4/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.5/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.7/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.8/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 92.9/101.1 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.0/101.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.1/101.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.2/101.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.3/101.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 93.4/101.1 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 93.5/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.6/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.7/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.7/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.8/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.9/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 93.9/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.0/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.1/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.2/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.2/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.3/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.4/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.4/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.5/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.5/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.5/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.6/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.6/101.1 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.7/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.8/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 94.9/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.0/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.1/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.2/101.1 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 95.5/101.1 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.6/101.1 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.7/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.8/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.9/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.1/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.1/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.2/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.3/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.5/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.6/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.6/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.8/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 96.9/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.0/101.1 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 97.1/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.2/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.3/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.4/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.6/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.7/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.8/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.9/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.0/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.1/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.2/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.2/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.4/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.5/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  98.6/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  98.7/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  98.8/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.0/101.1 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  99.1/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.3/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.8/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.1/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.2/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.4/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.4/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.5/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.8/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.0/101.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.1/101.1 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 2.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.4/1.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.7/1.3 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.3 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.9/1.3 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.9/1.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.0/1.3 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.0/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.1/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.2/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.1 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 41.0/47.1 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 47.1/47.1 kB 784.8 kB/s eta 0:00:00\n",
      "Installing collected packages: graphviz, lightgbm, catboost\n",
      "Successfully installed catboost-1.2.3 graphviz-0.20.3 lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cac865-f6bc-4906-a1e1-e765f2ed49d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVM:\n",
      "Accuracy: 0.6528\n",
      "Precision: 0.6578\n",
      "Recall: 0.6441\n",
      "F1 Score: 0.6500\n",
      "MCC: 0.3068\n",
      "\n",
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.5883\n",
      "Precision: 0.5949\n",
      "Recall: 0.5675\n",
      "F1 Score: 0.5797\n",
      "MCC: 0.1787\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "Accuracy: 0.6096\n",
      "Precision: 0.6136\n",
      "Recall: 0.6010\n",
      "F1 Score: 0.6063\n",
      "MCC: 0.2206\n",
      "\n",
      "\n",
      "Evaluating Gaussian Naive Bayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Gaussian Naive Bayes:\n",
      "Accuracy: 0.6524\n",
      "Precision: 0.6586\n",
      "Recall: 0.6383\n",
      "F1 Score: 0.6476\n",
      "MCC: 0.3057\n",
      "\n",
      "\n",
      "Evaluating Multinomial Naive Bayes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Multinomial Naive Bayes:\n",
      "Accuracy: 0.6546\n",
      "Precision: 0.6628\n",
      "Recall: 0.6355\n",
      "F1 Score: 0.6480\n",
      "MCC: 0.3104\n",
      "\n",
      "\n",
      "Evaluating K-NN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for K-NN:\n",
      "Accuracy: 0.5846\n",
      "Precision: 0.6146\n",
      "Recall: 0.4648\n",
      "F1 Score: 0.5279\n",
      "MCC: 0.1763\n",
      "\n",
      "\n",
      "Evaluating Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Gradient Boosting:\n",
      "Accuracy: 0.6245\n",
      "Precision: 0.6302\n",
      "Recall: 0.6075\n",
      "F1 Score: 0.6180\n",
      "MCC: 0.2497\n",
      "\n",
      "\n",
      "Evaluating AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for AdaBoost:\n",
      "Accuracy: 0.6042\n",
      "Precision: 0.6050\n",
      "Recall: 0.6007\n",
      "F1 Score: 0.6021\n",
      "MCC: 0.2088\n",
      "\n",
      "\n",
      "Evaluating Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree:\n",
      "Accuracy: 0.5245\n",
      "Precision: 0.5264\n",
      "Recall: 0.5177\n",
      "F1 Score: 0.5209\n",
      "MCC: 0.0505\n",
      "\n",
      "\n",
      "Evaluating Linear Discriminant Analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Linear Discriminant Analysis:\n",
      "Accuracy: 0.6096\n",
      "Precision: 0.6119\n",
      "Recall: 0.6053\n",
      "F1 Score: 0.6078\n",
      "MCC: 0.2203\n",
      "\n",
      "\n",
      "Evaluating Quadratic Discriminant Analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Quadratic Discriminant Analysis:\n",
      "Accuracy: 0.5187\n",
      "Precision: 0.5280\n",
      "Recall: 0.6466\n",
      "F1 Score: 0.5512\n",
      "MCC: 0.0434\n",
      "\n",
      "\n",
      "Evaluating Ridge Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Ridge Classifier:\n",
      "Accuracy: 0.6104\n",
      "Precision: 0.6128\n",
      "Recall: 0.6053\n",
      "F1 Score: 0.6082\n",
      "MCC: 0.2218\n",
      "\n",
      "\n",
      "Evaluating Perceptron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Perceptron:\n",
      "Accuracy: 0.5846\n",
      "Precision: 0.5869\n",
      "Recall: 0.6380\n",
      "F1 Score: 0.5918\n",
      "MCC: 0.1798\n",
      "\n",
      "\n",
      "Evaluating SGD Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SGD Classifier:\n",
      "Accuracy: 0.6006\n",
      "Precision: 0.6044\n",
      "Recall: 0.5921\n",
      "F1 Score: 0.5943\n",
      "MCC: 0.2029\n",
      "\n",
      "\n",
      "Evaluating Bagging Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Bagging Classifier:\n",
      "Accuracy: 0.5890\n",
      "Precision: 0.5994\n",
      "Recall: 0.5467\n",
      "F1 Score: 0.5702\n",
      "MCC: 0.1800\n",
      "\n",
      "\n",
      "Evaluating Extra Trees...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Extra Trees:\n",
      "Accuracy: 0.6165\n",
      "Precision: 0.6269\n",
      "Recall: 0.5865\n",
      "F1 Score: 0.6048\n",
      "MCC: 0.2357\n",
      "\n",
      "\n",
      "Evaluating CatBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for CatBoost:\n",
      "Accuracy: 0.6292\n",
      "Precision: 0.6332\n",
      "Recall: 0.6221\n",
      "F1 Score: 0.6267\n",
      "MCC: 0.2595\n",
      "\n",
      "\n",
      "Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1244, number of negative: 1239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501007 -> initscore=0.004027\n",
      "[LightGBM] [Info] Start training from score 0.004027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1245, number of negative: 1238\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501410 -> initscore=0.005638\n",
      "[LightGBM] [Info] Start training from score 0.005638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1244, number of negative: 1239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501007 -> initscore=0.004027\n",
      "[LightGBM] [Info] Start training from score 0.004027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1243, number of negative: 1240\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500604 -> initscore=0.002416\n",
      "[LightGBM] [Info] Start training from score 0.002416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1240, number of negative: 1243\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499396 -> initscore=-0.002416\n",
      "[LightGBM] [Info] Start training from score -0.002416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1257, number of negative: 1226\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506242 -> initscore=0.024971\n",
      "[LightGBM] [Info] Start training from score 0.024971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1243, number of negative: 1240\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500604 -> initscore=0.002416\n",
      "[LightGBM] [Info] Start training from score 0.002416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1249, number of negative: 1234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503021 -> initscore=0.012082\n",
      "[LightGBM] [Info] Start training from score 0.012082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1234, number of negative: 1249\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2483, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496979 -> initscore=-0.012082\n",
      "[LightGBM] [Info] Start training from score -0.012082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1248, number of negative: 1236\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 2484, number of used features: 804\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502415 -> initscore=0.009662\n",
      "[LightGBM] [Info] Start training from score 0.009662\n",
      "Results for LightGBM:\n",
      "Accuracy: 0.6241\n",
      "Precision: 0.6274\n",
      "Recall: 0.6209\n",
      "F1 Score: 0.6230\n",
      "MCC: 0.2494\n",
      "\n",
      "\n",
      "Evaluating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for XGBoost:\n",
      "Accuracy: 0.5999\n",
      "Precision: 0.6036\n",
      "Recall: 0.5945\n",
      "F1 Score: 0.5976\n",
      "MCC: 0.2013\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the function to load and preprocess the data\n",
    "def load_sequence_data(file_path, label):\n",
    "    \"\"\"Load sequence data from a file and label it.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().split(\"\\n\")\n",
    "    data = [list(sequence) for sequence in sequences if sequence]  # Exclude any empty lines\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = label\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load and label positive and negative data\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "\n",
    "# Combine the data\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "\n",
    "\n",
    "# Define classifiers in a dictionary\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'Ridge Classifier': RidgeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD Classifier': SGDClassifier(random_state=101),\n",
    "    'Bagging Classifier': BaggingClassifier(base_estimator=ExtraTreeClassifier(random_state=101), n_estimators=100, random_state=101),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=101),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(random_state=101),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=101)\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_classifier(X_train, y_train, classifier_name, classifier):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=101)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        if classifier_name == 'Multinomial Naive Bayes':\n",
    "            encoder = OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')\n",
    "            X_train_fold_enc = encoder.fit_transform(X_train_fold)\n",
    "            X_val_fold_enc = encoder.transform(X_val_fold)\n",
    "            classifier.fit(X_train_fold_enc, y_train_fold)\n",
    "            y_pred = classifier.predict(X_val_fold_enc)\n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "                ('encoder', OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')),\n",
    "                ('model', classifier)\n",
    "            ])\n",
    "            pipeline.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = pipeline.predict(X_val_fold)\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(y_val_fold, y_pred),\n",
    "            'Precision': precision_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'F1 Score': f1_score(y_val_fold, y_pred, zero_division=0),\n",
    "            'MCC': matthews_corrcoef(y_val_fold, y_pred)\n",
    "        }\n",
    "        \n",
    "        results.append(metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Execute evaluation for each classifier and print results\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    results = evaluate_classifier(X_train, y_train, name, clf)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    mean_results = results_df.mean()\n",
    "    print(f\"Results for {name}:\")\n",
    "    for metric, value in mean_results.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ce2fed-5576-488f-beff-b83b9180e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVM:\n",
      "    Accuracy: 0.7622\n",
      "    Precision: 0.7391\n",
      "    Recall: 0.7933\n",
      "    F1 Score: 0.7653\n",
      "\n",
      "Results for Random Forest:\n",
      "    Accuracy: 0.7134\n",
      "    Precision: 0.6914\n",
      "    Recall: 0.7467\n",
      "    F1 Score: 0.7179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "    Accuracy: 0.7231\n",
      "    Precision: 0.7211\n",
      "    Recall: 0.7067\n",
      "    F1 Score: 0.7138\n",
      "\n",
      "Results for Gaussian Naive Bayes:\n",
      "    Accuracy: 0.7980\n",
      "    Precision: 0.7785\n",
      "    Recall: 0.8200\n",
      "    F1 Score: 0.7987\n",
      "\n",
      "Results for K-NN:\n",
      "    Accuracy: 0.6840\n",
      "    Precision: 0.8046\n",
      "    Recall: 0.4667\n",
      "    F1 Score: 0.5907\n",
      "\n",
      "Results for Gradient Boosting:\n",
      "    Accuracy: 0.7068\n",
      "    Precision: 0.6765\n",
      "    Recall: 0.7667\n",
      "    F1 Score: 0.7188\n",
      "\n",
      "Results for AdaBoost:\n",
      "    Accuracy: 0.7622\n",
      "    Precision: 0.7452\n",
      "    Recall: 0.7800\n",
      "    F1 Score: 0.7622\n",
      "\n",
      "Results for Decision Tree:\n",
      "    Accuracy: 0.5798\n",
      "    Precision: 0.5652\n",
      "    Recall: 0.6067\n",
      "    F1 Score: 0.5852\n",
      "\n",
      "Results for Linear Discriminant Analysis:\n",
      "    Accuracy: 0.6743\n",
      "    Precision: 0.6623\n",
      "    Recall: 0.6800\n",
      "    F1 Score: 0.6711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Quadratic Discriminant Analysis:\n",
      "    Accuracy: 0.5212\n",
      "    Precision: 0.5283\n",
      "    Recall: 0.1867\n",
      "    F1 Score: 0.2759\n",
      "\n",
      "Results for Ridge Classifier:\n",
      "    Accuracy: 0.6743\n",
      "    Precision: 0.6623\n",
      "    Recall: 0.6800\n",
      "    F1 Score: 0.6711\n",
      "\n",
      "Results for Perceptron:\n",
      "    Accuracy: 0.7134\n",
      "    Precision: 0.7246\n",
      "    Recall: 0.6667\n",
      "    F1 Score: 0.6944\n",
      "\n",
      "Results for SGD Classifier:\n",
      "    Accuracy: 0.7134\n",
      "    Precision: 0.7153\n",
      "    Recall: 0.6867\n",
      "    F1 Score: 0.7007\n",
      "\n",
      "Results for CatBoost:\n",
      "    Accuracy: 0.7622\n",
      "    Precision: 0.7305\n",
      "    Recall: 0.8133\n",
      "    F1 Score: 0.7697\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1383, number of negative: 1376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2759, number of used features: 2004\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501269 -> initscore=0.005074\n",
      "[LightGBM] [Info] Start training from score 0.005074\n",
      "Results for LightGBM:\n",
      "    Accuracy: 0.7231\n",
      "    Precision: 0.7019\n",
      "    Recall: 0.7533\n",
      "    F1 Score: 0.7267\n",
      "\n",
      "Results for XGBoost:\n",
      "    Accuracy: 0.7134\n",
      "    Precision: 0.6937\n",
      "    Recall: 0.7400\n",
      "    F1 Score: 0.7161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ADMIN\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1383, number of negative: 1376\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4008\n",
      "[LightGBM] [Info] Number of data points in the train set: 2759, number of used features: 2004\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501269 -> initscore=0.005074\n",
      "[LightGBM] [Info] Start training from score 0.005074\n",
      "Voting Classifier Performance:\n",
      "    Accuracy: 0.7524\n",
      "    Precision: 0.7569\n",
      "    Recall: 0.7267\n",
      "    F1 Score: 0.7415\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().split(\"\\n\")\n",
    "    data = [list(sequence) for sequence in sequences if sequence]\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = label\n",
    "    return df\n",
    "\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(combined_data.drop('label', axis=1))\n",
    "y = combined_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.1, random_state=101)\n",
    "\n",
    "classifiers = {\n",
    "    'SVM': SVC(probability=True, random_state=101),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=101),\n",
    "    'Logistic Regression': LogisticRegression(random_state=101),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'K-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=101),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=101),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=101),\n",
    "    'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "    'Ridge Classifier': RidgeClassifier(random_state=101),\n",
    "    'Perceptron': Perceptron(random_state=101),\n",
    "    'SGD Classifier': SGDClassifier(random_state=101),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0, random_state=101),\n",
    "    'LightGBM': LGBMClassifier(random_state=101),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=101)\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(f\"    Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"    Precision: {precision_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"    Recall: {recall_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"    F1 Score: {f1_score(y_test, y_pred, zero_division=0):.4f}\\n\")\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[(name, clf) for name, clf in classifiers.items()], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred_vote = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"Voting Classifier Performance:\")\n",
    "print(f\"    Accuracy: {accuracy_score(y_test, y_pred_vote):.4f}\")\n",
    "print(f\"    Precision: {precision_score(y_test, y_pred_vote, zero_division=0):.4f}\")\n",
    "print(f\"    Recall: {recall_score(y_test, y_pred_vote, zero_division=0):.4f}\")\n",
    "print(f\"    F1 Score: {f1_score(y_test, y_pred_vote, zero_division=0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67071685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5115 - loss: 0.6977 - val_accuracy: 0.5781 - val_loss: 0.6922\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4995 - loss: 0.7017 - val_accuracy: 0.4219 - val_loss: 0.7204\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4806 - loss: 0.7145 - val_accuracy: 0.4219 - val_loss: 0.6977\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4724 - loss: 0.7021 - val_accuracy: 0.5781 - val_loss: 0.6824\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5367 - loss: 0.6945 - val_accuracy: 0.4219 - val_loss: 0.7031\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5247 - loss: 0.6992 - val_accuracy: 0.4219 - val_loss: 0.6946\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4399 - loss: 0.6991 - val_accuracy: 0.5781 - val_loss: 0.6911\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 0.6935 - val_accuracy: 0.4219 - val_loss: 0.6988\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5014 - loss: 0.6960 - val_accuracy: 0.5781 - val_loss: 0.6927\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4180 - loss: 0.6965 - val_accuracy: 0.4219 - val_loss: 0.6968\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5473 - loss: 0.6913  \n",
      "Test Accuracy: 56.34%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    \"\"\"Load sequence data from a file and label it.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().split(\"\\n\")\n",
    "    data = [list(sequence) for sequence in sequences if sequence]  # Exclude empty lines\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = label\n",
    "    return df\n",
    "\n",
    "# Load and label the data\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "# Convert sequences to integers\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = X.applymap(lambda x: label_encoder.fit_transform([x])[0])\n",
    "\n",
    "# One-hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
    "X_onehot = onehot_encoder.fit_transform(X_encoded)\n",
    "\n",
    "# Reshape data for Conv1D layer\n",
    "sequence_length = X_onehot.shape[1]\n",
    "X_reshaped = X_onehot.reshape((X_onehot.shape[0], sequence_length, 1))\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.1, random_state=101)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(sequence_length, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)  # Adjust epochs, add callbacks as needed\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79c13b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5279 - loss: 0.6976\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59130, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.5277 - loss: 0.6975 - val_accuracy: 0.5913 - val_loss: 0.6926\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5255 - loss: 0.6829\n",
      "Epoch 2: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5271 - loss: 0.6828 - val_accuracy: 0.4870 - val_loss: 0.6929\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6277 - loss: 0.6443\n",
      "Epoch 3: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6268 - loss: 0.6462 - val_accuracy: 0.4783 - val_loss: 0.6927\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6575 - loss: 0.6088\n",
      "Epoch 4: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6539 - loss: 0.6131 - val_accuracy: 0.4870 - val_loss: 0.6920\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6458 - loss: 0.6364\n",
      "Epoch 5: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6496 - loss: 0.6348 - val_accuracy: 0.4870 - val_loss: 0.6898\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6716 - loss: 0.6146\n",
      "Epoch 6: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6684 - loss: 0.6161 - val_accuracy: 0.4957 - val_loss: 0.6872\n",
      "Epoch 7/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6569 - loss: 0.6215\n",
      "Epoch 7: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6606 - loss: 0.6181 - val_accuracy: 0.4783 - val_loss: 0.6935\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6527 - loss: 0.6145\n",
      "Epoch 8: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6563 - loss: 0.6093 - val_accuracy: 0.4870 - val_loss: 0.6876\n",
      "Epoch 9/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7200 - loss: 0.5475\n",
      "Epoch 9: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7191 - loss: 0.5473 - val_accuracy: 0.4870 - val_loss: 0.7043\n",
      "Epoch 10/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7290 - loss: 0.5361\n",
      "Epoch 10: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7297 - loss: 0.5389 - val_accuracy: 0.4957 - val_loss: 0.6812\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7208 - loss: 0.5837\n",
      "Epoch 11: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7195 - loss: 0.5835 - val_accuracy: 0.5304 - val_loss: 0.6866\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7083 - loss: 0.5678\n",
      "Epoch 12: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7081 - loss: 0.5681 - val_accuracy: 0.5043 - val_loss: 0.6881\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7388 - loss: 0.5154\n",
      "Epoch 13: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7395 - loss: 0.5154 - val_accuracy: 0.5652 - val_loss: 0.6859\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7244 - loss: 0.5221\n",
      "Epoch 14: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7259 - loss: 0.5190 - val_accuracy: 0.5565 - val_loss: 0.6804\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7895 - loss: 0.5166\n",
      "Epoch 15: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7825 - loss: 0.5209 - val_accuracy: 0.5826 - val_loss: 0.6808\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7786 - loss: 0.4756\n",
      "Epoch 16: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7729 - loss: 0.4847 - val_accuracy: 0.5304 - val_loss: 0.7024\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7769 - loss: 0.5039\n",
      "Epoch 17: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7758 - loss: 0.5010 - val_accuracy: 0.5652 - val_loss: 0.6793\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8171 - loss: 0.4300\n",
      "Epoch 18: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8123 - loss: 0.4372 - val_accuracy: 0.5565 - val_loss: 0.6858\n",
      "Epoch 19/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8284 - loss: 0.4133\n",
      "Epoch 19: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8233 - loss: 0.4191 - val_accuracy: 0.5391 - val_loss: 0.7064\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7864 - loss: 0.4469\n",
      "Epoch 20: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7855 - loss: 0.4440 - val_accuracy: 0.5826 - val_loss: 0.7177\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8118 - loss: 0.4283\n",
      "Epoch 21: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8094 - loss: 0.4284 - val_accuracy: 0.5217 - val_loss: 0.7886\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7868 - loss: 0.4867\n",
      "Epoch 22: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7873 - loss: 0.4866 - val_accuracy: 0.5304 - val_loss: 0.7577\n",
      "Epoch 23/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8526 - loss: 0.3447\n",
      "Epoch 23: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8502 - loss: 0.3500 - val_accuracy: 0.5304 - val_loss: 0.8160\n",
      "Epoch 24/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8566 - loss: 0.3547\n",
      "Epoch 24: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8515 - loss: 0.3633 - val_accuracy: 0.5217 - val_loss: 0.8248\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8002 - loss: 0.3767\n",
      "Epoch 25: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8006 - loss: 0.3781 - val_accuracy: 0.5391 - val_loss: 0.8266\n",
      "Epoch 26/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8313 - loss: 0.3706\n",
      "Epoch 26: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8324 - loss: 0.3712 - val_accuracy: 0.5043 - val_loss: 0.9342\n",
      "Epoch 27/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8537 - loss: 0.3225\n",
      "Epoch 27: val_accuracy did not improve from 0.59130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8525 - loss: 0.3268 - val_accuracy: 0.5565 - val_loss: 1.0385\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "Test Accuracy: 65.73%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().strip().split(\"\\n\")\n",
    "    data = {'sequence': sequences, 'label': [label] * len(sequences)}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def preprocess_sequences(sequences, padding_value='N'):\n",
    "    all_characters = [char for seq in sequences for char in seq] + [padding_value]\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_characters)\n",
    "    encoded_seqs = [label_encoder.transform(list(seq)) for seq in sequences]\n",
    "    padded_seqs = pad_sequences(encoded_seqs, padding='post', value=label_encoder.transform([padding_value])[0])\n",
    "    return padded_seqs\n",
    "\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "max_seq_length = combined_data['sequence'].apply(len).max()\n",
    "X = preprocess_sequences(combined_data['sequence'], padding_value='N')\n",
    "y = combined_data['label'].values\n",
    "\n",
    "seq_length = X.shape[1]\n",
    "vocab_size = len(np.unique(X)) + 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_compiled_model(seq_length, vocab_size):\n",
    "    input_layer = Input(shape=(seq_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=50)(input_layer)\n",
    "    x = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_compiled_model(seq_length, vocab_size)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stopping, model_checkpoint], verbose=1)\n",
    "\n",
    "model.load_weights('best_model.keras')\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1524c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4725 - loss: 0.6987\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48696, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4750 - loss: 0.6985 - val_accuracy: 0.4870 - val_loss: 0.6929\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5635 - loss: 0.6675\n",
      "Epoch 2: val_accuracy did not improve from 0.48696\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5647 - loss: 0.6674 - val_accuracy: 0.4783 - val_loss: 0.6910\n",
      "Epoch 3/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6132 - loss: 0.6458\n",
      "Epoch 3: val_accuracy improved from 0.48696 to 0.52174, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6135 - loss: 0.6453 - val_accuracy: 0.5217 - val_loss: 0.6886\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6298 - loss: 0.6426\n",
      "Epoch 4: val_accuracy did not improve from 0.52174\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6298 - loss: 0.6429 - val_accuracy: 0.5217 - val_loss: 0.6866\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6675 - loss: 0.6073\n",
      "Epoch 5: val_accuracy improved from 0.52174 to 0.53043, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6666 - loss: 0.6078 - val_accuracy: 0.5304 - val_loss: 0.6857\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6981 - loss: 0.5976\n",
      "Epoch 6: val_accuracy did not improve from 0.53043\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.6987 - loss: 0.5974 - val_accuracy: 0.5130 - val_loss: 0.6863\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7128 - loss: 0.5831\n",
      "Epoch 7: val_accuracy did not improve from 0.53043\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7115 - loss: 0.5835 - val_accuracy: 0.5043 - val_loss: 0.6864\n",
      "Epoch 8/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6621 - loss: 0.5861\n",
      "Epoch 8: val_accuracy did not improve from 0.53043\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6648 - loss: 0.5838 - val_accuracy: 0.4957 - val_loss: 0.6914\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6820 - loss: 0.5729\n",
      "Epoch 9: val_accuracy improved from 0.53043 to 0.53913, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6828 - loss: 0.5732 - val_accuracy: 0.5391 - val_loss: 0.6861\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7168 - loss: 0.5555\n",
      "Epoch 10: val_accuracy did not improve from 0.53913\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7151 - loss: 0.5548 - val_accuracy: 0.5391 - val_loss: 0.6844\n",
      "Epoch 11/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7242 - loss: 0.5423\n",
      "Epoch 11: val_accuracy improved from 0.53913 to 0.61739, saving model to best_model.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7233 - loss: 0.5444 - val_accuracy: 0.6174 - val_loss: 0.6741\n",
      "Epoch 12/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7419 - loss: 0.5311\n",
      "Epoch 12: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7399 - loss: 0.5305 - val_accuracy: 0.6000 - val_loss: 0.6756\n",
      "Epoch 13/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7338 - loss: 0.5320\n",
      "Epoch 13: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7342 - loss: 0.5289 - val_accuracy: 0.5652 - val_loss: 0.6819\n",
      "Epoch 14/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7430 - loss: 0.5050\n",
      "Epoch 14: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7433 - loss: 0.5031 - val_accuracy: 0.5913 - val_loss: 0.6754\n",
      "Epoch 15/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7476 - loss: 0.4989\n",
      "Epoch 15: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7476 - loss: 0.4981 - val_accuracy: 0.5826 - val_loss: 0.6797\n",
      "Epoch 16/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7467 - loss: 0.4943\n",
      "Epoch 16: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7493 - loss: 0.4949 - val_accuracy: 0.5739 - val_loss: 0.6694\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7853 - loss: 0.4518\n",
      "Epoch 17: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7842 - loss: 0.4517 - val_accuracy: 0.5826 - val_loss: 0.6785\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7841 - loss: 0.4513\n",
      "Epoch 18: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7803 - loss: 0.4550 - val_accuracy: 0.5739 - val_loss: 0.7018\n",
      "Epoch 19/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8058 - loss: 0.4410\n",
      "Epoch 19: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8024 - loss: 0.4464 - val_accuracy: 0.5739 - val_loss: 0.7355\n",
      "Epoch 20/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7753 - loss: 0.4677\n",
      "Epoch 20: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7752 - loss: 0.4663 - val_accuracy: 0.5478 - val_loss: 0.7278\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8083 - loss: 0.3967\n",
      "Epoch 21: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8081 - loss: 0.3975 - val_accuracy: 0.5739 - val_loss: 0.7529\n",
      "Epoch 22/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7934 - loss: 0.4236\n",
      "Epoch 22: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7926 - loss: 0.4264 - val_accuracy: 0.5913 - val_loss: 0.7662\n",
      "Epoch 23/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8282 - loss: 0.4121\n",
      "Epoch 23: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8304 - loss: 0.4107 - val_accuracy: 0.6000 - val_loss: 0.7774\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8384 - loss: 0.3684\n",
      "Epoch 24: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8379 - loss: 0.3688 - val_accuracy: 0.5391 - val_loss: 0.8476\n",
      "Epoch 25/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8233 - loss: 0.3942\n",
      "Epoch 25: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8256 - loss: 0.3931 - val_accuracy: 0.5391 - val_loss: 0.8864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8423 - loss: 0.3440\n",
      "Epoch 26: val_accuracy did not improve from 0.61739\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8405 - loss: 0.3469 - val_accuracy: 0.5478 - val_loss: 0.8170\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Test Accuracy: 65.73%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_sequence_data(file_path, label):\n",
    "    \"\"\"Load sequence data from a file and assign labels.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().strip().split(\"\\n\")\n",
    "    data = {'sequence': sequences, 'label': [label] * len(sequences)}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def preprocess_sequences(sequences, padding_value='N'):\n",
    "    \"\"\"Encode sequences using LabelEncoder and pad them.\"\"\"\n",
    "    label_encoder = LabelEncoder().fit(list(set(''.join(sequences) + padding_value)))\n",
    "    encoded_seqs = [label_encoder.transform(list(seq)) for seq in sequences]\n",
    "    padded_seqs = pad_sequences(encoded_seqs, padding='post', value=label_encoder.transform([padding_value])[0])\n",
    "    return padded_seqs\n",
    "\n",
    "# Load and combine data\n",
    "pos_data = load_sequence_data(\"oripos.txt\", 1)\n",
    "neg_data = load_sequence_data(\"orineg.txt\", 0)\n",
    "combined_data = pd.concat([pos_data, neg_data], ignore_index=True)\n",
    "\n",
    "# Preprocess sequences\n",
    "max_seq_length = combined_data['sequence'].apply(len).max()\n",
    "X = preprocess_sequences(combined_data['sequence'], padding_value='N')\n",
    "y = combined_data['label'].values\n",
    "\n",
    "# Prepare data for training\n",
    "seq_length = X.shape[1]\n",
    "vocab_size = np.max(X) + 1  # Updated to directly compute the vocab size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def get_compiled_model(seq_length, vocab_size):\n",
    "    \"\"\"Define and compile the model.\"\"\"\n",
    "    input_layer = Input(shape=(seq_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=50)(input_layer)\n",
    "    x = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_compiled_model(seq_length, vocab_size)\n",
    "\n",
    "# Setup callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stopping, model_checkpoint], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "model.load_weights('best_model.keras')\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cadb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5789 - loss: 0.6647\n",
      "Epoch 1: val_accuracy improved from -inf to 0.51120, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 196ms/step - accuracy: 0.5798 - loss: 0.6641 - val_accuracy: 0.5112 - val_loss: 0.7029\n",
      "Epoch 2/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7072 - loss: 0.5940\n",
      "Epoch 2: val_accuracy did not improve from 0.51120\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 137ms/step - accuracy: 0.7071 - loss: 0.5939 - val_accuracy: 0.5112 - val_loss: 0.9496\n",
      "Epoch 3/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7001 - loss: 0.5779\n",
      "Epoch 3: val_accuracy did not improve from 0.51120\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.7000 - loss: 0.5780 - val_accuracy: 0.5112 - val_loss: 0.9096\n",
      "Epoch 4/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.6931 - loss: 0.5775\n",
      "Epoch 4: val_accuracy did not improve from 0.51120\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - accuracy: 0.6932 - loss: 0.5774 - val_accuracy: 0.5112 - val_loss: 0.8750\n",
      "Epoch 5/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7274 - loss: 0.5578\n",
      "Epoch 5: val_accuracy improved from 0.51120 to 0.54582, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.7271 - loss: 0.5580 - val_accuracy: 0.5458 - val_loss: 0.7017\n",
      "Epoch 6/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7121 - loss: 0.5706\n",
      "Epoch 6: val_accuracy improved from 0.54582 to 0.64358, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.7120 - loss: 0.5706 - val_accuracy: 0.6436 - val_loss: 0.6346\n",
      "Epoch 7/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7145 - loss: 0.5630\n",
      "Epoch 7: val_accuracy improved from 0.64358 to 0.66395, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 141ms/step - accuracy: 0.7144 - loss: 0.5633 - val_accuracy: 0.6640 - val_loss: 0.6135\n",
      "Epoch 8/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7165 - loss: 0.5562\n",
      "Epoch 8: val_accuracy improved from 0.66395 to 0.67617, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.7165 - loss: 0.5563 - val_accuracy: 0.6762 - val_loss: 0.6556\n",
      "Epoch 9/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7121 - loss: 0.5629\n",
      "Epoch 9: val_accuracy improved from 0.67617 to 0.69857, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.7122 - loss: 0.5628 - val_accuracy: 0.6986 - val_loss: 0.5948\n",
      "Epoch 10/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7144 - loss: 0.5709\n",
      "Epoch 10: val_accuracy did not improve from 0.69857\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 150ms/step - accuracy: 0.7143 - loss: 0.5708 - val_accuracy: 0.6965 - val_loss: 0.6255\n",
      "Epoch 11/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7084 - loss: 0.5729\n",
      "Epoch 11: val_accuracy did not improve from 0.69857\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - accuracy: 0.7085 - loss: 0.5726 - val_accuracy: 0.6864 - val_loss: 0.6577\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6984 - loss: 0.5535\n",
      "Epoch 12: val_accuracy did not improve from 0.69857\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.6986 - loss: 0.5535 - val_accuracy: 0.6925 - val_loss: 0.6368\n",
      "Epoch 13/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7143 - loss: 0.5567\n",
      "Epoch 13: val_accuracy did not improve from 0.69857\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - accuracy: 0.7144 - loss: 0.5565 - val_accuracy: 0.6578 - val_loss: 0.6945\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7144 - loss: 0.5586\n",
      "Epoch 14: val_accuracy improved from 0.69857 to 0.71079, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - accuracy: 0.7144 - loss: 0.5585 - val_accuracy: 0.7108 - val_loss: 0.6168\n",
      "Epoch 15/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7174 - loss: 0.5487\n",
      "Epoch 15: val_accuracy improved from 0.71079 to 0.71487, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.7175 - loss: 0.5487 - val_accuracy: 0.7149 - val_loss: 0.5844\n",
      "Epoch 16/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7432 - loss: 0.5299\n",
      "Epoch 16: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - accuracy: 0.7432 - loss: 0.5301 - val_accuracy: 0.6965 - val_loss: 0.6065\n",
      "Epoch 17/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7338 - loss: 0.5412\n",
      "Epoch 17: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.7337 - loss: 0.5413 - val_accuracy: 0.6782 - val_loss: 0.6637\n",
      "Epoch 18/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7264 - loss: 0.5344\n",
      "Epoch 18: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.7263 - loss: 0.5346 - val_accuracy: 0.6925 - val_loss: 0.6531\n",
      "Epoch 19/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7152 - loss: 0.5607\n",
      "Epoch 19: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.7153 - loss: 0.5602 - val_accuracy: 0.6986 - val_loss: 0.6058\n",
      "Epoch 20/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7358 - loss: 0.5353\n",
      "Epoch 20: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step - accuracy: 0.7359 - loss: 0.5352 - val_accuracy: 0.7128 - val_loss: 0.5974\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7506 - loss: 0.5265\n",
      "Epoch 21: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.7505 - loss: 0.5265 - val_accuracy: 0.7026 - val_loss: 0.5619\n",
      "Epoch 22/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7611 - loss: 0.4994\n",
      "Epoch 22: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.7608 - loss: 0.4997 - val_accuracy: 0.6864 - val_loss: 0.5893\n",
      "Epoch 23/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7554 - loss: 0.5112\n",
      "Epoch 23: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - accuracy: 0.7552 - loss: 0.5114 - val_accuracy: 0.7026 - val_loss: 0.6076\n",
      "Epoch 24/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7433 - loss: 0.5079\n",
      "Epoch 24: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.7432 - loss: 0.5080 - val_accuracy: 0.7006 - val_loss: 0.6183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7657 - loss: 0.4989\n",
      "Epoch 25: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 139ms/step - accuracy: 0.7654 - loss: 0.4991 - val_accuracy: 0.7149 - val_loss: 0.6109\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7453 - loss: 0.5224\n",
      "Epoch 26: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - accuracy: 0.7454 - loss: 0.5223 - val_accuracy: 0.6864 - val_loss: 0.6531\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7551 - loss: 0.4911\n",
      "Epoch 27: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 163ms/step - accuracy: 0.7551 - loss: 0.4912 - val_accuracy: 0.6884 - val_loss: 0.6103\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7665 - loss: 0.4994\n",
      "Epoch 28: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - accuracy: 0.7663 - loss: 0.4996 - val_accuracy: 0.7128 - val_loss: 0.5779\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7686 - loss: 0.5050\n",
      "Epoch 29: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - accuracy: 0.7686 - loss: 0.5049 - val_accuracy: 0.7026 - val_loss: 0.5931\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7483 - loss: 0.4890\n",
      "Epoch 30: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.7484 - loss: 0.4890 - val_accuracy: 0.7128 - val_loss: 0.5964\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7717 - loss: 0.4741\n",
      "Epoch 31: val_accuracy did not improve from 0.71487\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 140ms/step - accuracy: 0.7715 - loss: 0.4744 - val_accuracy: 0.7026 - val_loss: 0.6203\n",
      "Epoch 32/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7552 - loss: 0.4792\n",
      "Epoch 32: val_accuracy improved from 0.71487 to 0.72505, saving model to best_model_Arabidopsis_correct_10001.keras\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - accuracy: 0.7552 - loss: 0.4794 - val_accuracy: 0.7251 - val_loss: 0.5882\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7719 - loss: 0.4808\n",
      "Epoch 33: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.7718 - loss: 0.4806 - val_accuracy: 0.7169 - val_loss: 0.6044\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7863 - loss: 0.4585\n",
      "Epoch 34: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 127ms/step - accuracy: 0.7859 - loss: 0.4590 - val_accuracy: 0.6945 - val_loss: 0.5962\n",
      "Epoch 35/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7921 - loss: 0.4558\n",
      "Epoch 35: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 126ms/step - accuracy: 0.7919 - loss: 0.4560 - val_accuracy: 0.6986 - val_loss: 0.6142\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7793 - loss: 0.4545\n",
      "Epoch 36: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - accuracy: 0.7793 - loss: 0.4548 - val_accuracy: 0.6945 - val_loss: 0.6435\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7637 - loss: 0.4954\n",
      "Epoch 37: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 125ms/step - accuracy: 0.7637 - loss: 0.4951 - val_accuracy: 0.7108 - val_loss: 0.6165\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7796 - loss: 0.4616\n",
      "Epoch 38: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.7796 - loss: 0.4617 - val_accuracy: 0.7251 - val_loss: 0.6068\n",
      "Epoch 39/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.8017 - loss: 0.4358\n",
      "Epoch 39: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - accuracy: 0.8015 - loss: 0.4362 - val_accuracy: 0.7210 - val_loss: 0.6106\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7810 - loss: 0.4470\n",
      "Epoch 40: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.7809 - loss: 0.4470 - val_accuracy: 0.6904 - val_loss: 0.6216\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7828 - loss: 0.4346\n",
      "Epoch 41: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.7829 - loss: 0.4346 - val_accuracy: 0.6965 - val_loss: 0.6894\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8096 - loss: 0.3996\n",
      "Epoch 42: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - accuracy: 0.8093 - loss: 0.4000 - val_accuracy: 0.6802 - val_loss: 0.6898\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.8117 - loss: 0.4045\n",
      "Epoch 43: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - accuracy: 0.8116 - loss: 0.4047 - val_accuracy: 0.6701 - val_loss: 0.7663\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8129 - loss: 0.4214\n",
      "Epoch 44: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - accuracy: 0.8128 - loss: 0.4215 - val_accuracy: 0.6843 - val_loss: 0.6677\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.8151 - loss: 0.3880\n",
      "Epoch 45: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - accuracy: 0.8150 - loss: 0.3882 - val_accuracy: 0.6945 - val_loss: 0.6955\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.8332 - loss: 0.3566\n",
      "Epoch 46: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - accuracy: 0.8330 - loss: 0.3570 - val_accuracy: 0.6823 - val_loss: 0.6908\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8441 - loss: 0.3651\n",
      "Epoch 47: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 139ms/step - accuracy: 0.8438 - loss: 0.3654 - val_accuracy: 0.6782 - val_loss: 0.6770\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8344 - loss: 0.3670\n",
      "Epoch 48: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 153ms/step - accuracy: 0.8343 - loss: 0.3672 - val_accuracy: 0.6538 - val_loss: 0.7707\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8345 - loss: 0.3605\n",
      "Epoch 49: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - accuracy: 0.8345 - loss: 0.3605 - val_accuracy: 0.7026 - val_loss: 0.7186\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8378 - loss: 0.3612\n",
      "Epoch 50: val_accuracy did not improve from 0.72505\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.8378 - loss: 0.3613 - val_accuracy: 0.6945 - val_loss: 0.7050\n",
      "Arabidopsis_correct_10001 - Test Accuracy: 68.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, BatchNormalization, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_and_process_sequences(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sequences = file.read().strip().split(\"\\n\")\n",
    "    \n",
    "    pos_data = [seq[5000:5301] for seq in sequences]\n",
    "    neg_data = [seq[8000:8301] for seq in sequences]  # Use only the 8000-8201 region for negative data\n",
    "    \n",
    "    combined_data = [{'sequence': seq, 'label': 1} for seq in pos_data] + [{'sequence': seq, 'label': 0} for seq in neg_data]\n",
    "    return pd.DataFrame(combined_data)\n",
    "\n",
    "def preprocess_sequences(sequences):\n",
    "    label_encoder = LabelEncoder().fit(list(set(''.join(sequences))))\n",
    "    encoded_seqs = [label_encoder.transform(list(seq)) for seq in sequences]\n",
    "    return np.array(encoded_seqs)\n",
    "\n",
    "def get_compiled_model(seq_length, vocab_size):\n",
    "    input_layer = Input(shape=(seq_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=50)(input_layer)\n",
    "    \n",
    "    # Deepen the network with additional layers\n",
    "    for _ in range(3):  # Example to add 3 sets of Conv, BatchNorm, MaxPool, Dropout\n",
    "        x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Bidirectional(LSTM(128))(x)  # Increased LSTM units\n",
    "    x = Dense(256, activation='relu')(x)  # Increased Dense layer units\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "files = [\"Arabidopsis_correct_10001\"]\n",
    "#files = [\"Arabidopsis_correct_10001\", \"Candiada_correct_10001\", \"DM3_10001\", \n",
    "#         \"Kluy_correct_10001\", \"MM8_correct_10001\", \"Pichia_correct_10001\",\n",
    "#         \"Sacharo_correct_10001\", \"Schizo_correct_10001\"]\n",
    "\n",
    "for file in files:\n",
    "    combined_data = load_and_process_sequences(f\"{file}\")\n",
    "    X = preprocess_sequences(combined_data['sequence'])\n",
    "    y = combined_data['label'].values\n",
    "\n",
    "    seq_length = X.shape[1]\n",
    "    vocab_size = len(np.unique(X))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = get_compiled_model(seq_length, vocab_size)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{file}.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[model_checkpoint], verbose=1)\n",
    "\n",
    "    model.load_weights(f'best_model_{file}.keras')\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'{file} - Test Accuracy: {accuracy*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738165db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def load_and_process_sequence(file_name):\n",
    "    with open(file_name, \"r\") as file:\n",
    "        sequences = file.read().strip().split(\"\\n\")\n",
    "\n",
    "    pos_data = [seq[4900:5101] for seq in sequences]\n",
    "    neg_data = [seq[8000:8201] for seq in sequences]\n",
    "\n",
    "    combined_data = [{'sequence': seq, 'label': 1} for seq in pos_data] + [{'sequence': seq, 'label': 0} for seq in neg_data]\n",
    "    return pd.DataFrame(combined_data)\n",
    "\n",
    "def one_hot_encode_sequences_optimized(sequences):\n",
    "    # Create an array of the sequences\n",
    "    seq_array = np.array(sequences)\n",
    "\n",
    "    # Define a mapping for each character to an integer\n",
    "    char_to_int = np.array(['A', 'C', 'G', 'T'])\n",
    "\n",
    "    # Initialize the encoded array\n",
    "    encoded_seqs = np.zeros((seq_array.shape[0], seq_array.shape[1], 4))\n",
    "\n",
    "    # Iterate through each character and one-hot encode\n",
    "    for i, char in enumerate(char_to_int):\n",
    "        encoded_seqs[seq_array == char, i] = 1\n",
    "\n",
    "    return encoded_seqs\n",
    "\n",
    "def get_compiled_model(seq_length):\n",
    "    input_layer = tf.keras.layers.Input(shape=(seq_length, 4), name='input')\n",
    "    \n",
    "    # Convolutional and Pooling layers\n",
    "    x = tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(input_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=32, kernel_size=5, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.AvgPool1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.AvgPool1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.AvgPool1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=256, kernel_size=5, activation=tf.nn.relu6, strides=1, kernel_regularizer=tf.keras.regularizers.L1L2())(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.AvgPool1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # LSTM layer\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Reshape((1, -1))(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=1024, activation='relu', return_sequences=False))(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(units=1024, activation='relu')(x)\n",
    "    output_layer = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "def load_and_process_sequences_parallel(files):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        combined_data = list(executor.map(load_and_process_sequence, files))\n",
    "    return pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# Sample file names for demonstration (these need to be actual file paths in practice)\n",
    "files = [\"file1\", \"file2\", \"file3\"]\n",
    "\n",
    "# Load and process sequences in parallel\n",
    "combined_data = load_and_process_sequences_parallel(files)\n",
    "\n",
    "# One-hot encode sequences\n",
    "X = one_hot_encode_sequences_optimized(combined_data['sequence'])\n",
    "\n",
    "# Convert labels to categorical\n",
    "y = to_categorical(combined_data['label'].values)\n",
    "\n",
    "# Get sequence length\n",
    "seq_length = X.shape[1]\n",
    "\n",
    "# Compile the model\n",
    "model = get_compiled_model(seq_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "# Note: Actual file paths need to be used in place of \"file1\", \"file2\", \"file3\" for this code to run successfully.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
